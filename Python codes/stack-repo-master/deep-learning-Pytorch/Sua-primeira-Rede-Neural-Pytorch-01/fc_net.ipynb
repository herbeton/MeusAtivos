{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Stack</center></h1>\n",
    "<h2><center> Deep Learning com Pytorch</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos o conjunto de dados MNIST que consiste em dígitos manuscritos em escala de cinza. Cada imagem é 28x28 pixels.Vamos dar uma olhada nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"mnist.png\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/vision/stable/datasets.html?highlight=mnist#emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download dados de treino\n",
    "trainset = datasets.MNIST('~/.pytorch_data/MNIST_data/', download=True, train=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: C:\\Users\\borge/.pytorch_data/MNIST_data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5,), std=(0.5,))\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x15138bcceb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classe DataLoader em PyTorch  nos ajuda a carregar e iterar sobre elementos em um conjunto de dados. Esta classe está disponível como DataLoader no módulo torch.utils.data module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora nós temos os dados de treinamento no objeto trainloader. Vamos criar um interator em trainloader para que possamos fazer loop nos dados MNIST.\n",
    "\n",
    "Nosso trainloader possui seguintes caracteristicas:\n",
    "- Batch tamanho 10\n",
    "    - Representa o número de imagens que nós vamos utilizar a cada iteração que passamos na nossa rede neural.\n",
    "- Shuffle = True \n",
    "    - Para embaralhar os dados\n",
    "    \n",
    "Vamos dar uma olhada na primeira Batch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image type: <class 'torch.Tensor'>\n",
      "image shape: torch.Size([10, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print('image type:',type(images))\n",
    "print(\"image shape:\", images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape: torch.Size([10])\n",
      "labels:  tensor([5, 1, 0, 0, 9, 0, 9, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "print('labels shape:',labels.shape)\n",
    "print(\"labels: \",labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que as imagens são tensores com shape **[10, 1, 28, 28]**. Ou seja, temos aqui **10 imagens por batch com um color channel ( cinza ) e 28 x 28 pixels por imagem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0].numpy().squeeze());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando a Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"net.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"fc.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"activation_functions-1.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transforma cada entrada em valores entre 0 e 1 e os normaliza para lhes dar uma distribuição de probabilidade adequada onde as probabilidades somam-se a 1.\n",
    "    *  [**softmax function**](https://en.wikipedia.org/wiki/Softmax_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\sigma(x_i) = \\frac{e^{x_i}} {\\sum_k^K{e^{x_k}}}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"dp-diagram.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"pixel_image.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"flatten.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\n",
    "* Fonte das imagens: \n",
    " * [Diagrama criado no site draw.io](https://app.diagrams.net/)\n",
    " * [imagem em pixels](https://www.ovh.com/blog/deep-learning-explained-to-my-8-year-old-daughter/)\n",
    " * [imagem com flatten](https://www.w3resource.com/w3r_images/numpy-manipulation-ndarray-flatten-function-image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses em Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [LogSoftMax](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\sigma(x_i) = \\frac{e^{x_i}} {\\sum_k^K{e^{x_k}}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"logSoftMax.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Negative log likelihood loss ( NLLLoss ) é útil treinar um problema de classificação com classes C.\n",
    "    * [**NLLLoss**](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html)\n",
    "    * [**Outras loss functions**](https://pytorch.org/docs/stable/nn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A gente vai construir o modelo com uma saída **log-softmax** usando nn.LogSoftmax e depois obtemos as probabilidades reais tomando o exponencial torch.exp.\n",
    "* Com uma saída log-softmax, podemos calcular a negative log likelihood loss, **nn.NLLLoss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden_1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (Relu): ReLU()\n",
       "  (LogSoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs da camada escondida (ou hidden layer) - transformação linear\n",
    "        self.hidden_1 = nn.Linear(784, 128)\n",
    "        self.hidden_2 = nn.Linear(128,64)\n",
    "        \n",
    "        # camada de saida (ou Output layer) , 10 neurônios ou unidades - um para cada dígito do nosso dataset ( 0,1,2,3,4,5,6,7,8,9)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "        # Define Relu activation e LogSoftmax output \n",
    "        self.Relu = nn.ReLU()\n",
    "        self.LogSoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass o vetor de input em cada uma das nossas operações\n",
    "        x = self.hidden_1(x)\n",
    "        x = self.Relu(x)\n",
    "        \n",
    "        x = self.hidden_2(x)\n",
    "        x = self.Relu(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        x = self.LogSoftmax(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "modelo = Network()\n",
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images (shape):  torch.Size([10, 1, 28, 28])\n",
      "images.shape[0]:  10\n",
      "images.view(images.shape[0], -1).shape:  torch.Size([10, 784])\n"
     ]
    }
   ],
   "source": [
    "print(\"images (shape): \",images.shape)\n",
    "print(\"images.shape[0]: \", images.shape[0])\n",
    "print(\"images.view(images.shape[0], -1).shape: \", images.view(images.shape[0], -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\borge\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Treino: 0.7409363886499778\n",
      "Loss Treino: 0.3205686016249626\n",
      "Loss Treino: 0.2655872146798453\n",
      "Loss Treino: 0.22562309535592795\n",
      "Loss Treino: 0.19489755468008418\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(modelo.parameters(), lr=0.003)\n",
    "\n",
    "epocas = 5\n",
    "for epoca in range(epocas):\n",
    "    loss_ = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten imagem em vetor de 784 elementos\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = modelo.forward(images)     \n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_ += loss.item()\n",
    "    else:\n",
    "        print(f\"Loss Treino: {loss_/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# torch.Size([1, 784]\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "# Bloqueia o calculo de gradiente - usado para avaliação\n",
    "with torch.no_grad():\n",
    "    logs = modelo(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "p = torch.exp(logs)\n",
    "p = p.data.numpy().squeeze()\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(10,9), ncols=2)\n",
    "ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "ax1.axis('off')\n",
    "ax2.barh(np.arange(10), p)\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(10))\n",
    "\n",
    "ax2.set_yticklabels(np.arange(10))\n",
    "\n",
    "ax2.set_title('Probabilidade')\n",
    "ax2.set_xlim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uma Outra forma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Treino: 0.7170689324066043\n",
      "Loss Treino: 0.31889288167810687\n",
      "Loss Treino: 0.26555575819693816\n",
      "Loss Treino: 0.22472569833230227\n",
      "Loss Treino: 0.19165358735946939\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Quando tems iterações de backpropagations com os mesmos parâmetros, os gradientes são acumulados.  \n",
    "        # Por isso precisamos zerar os gradientes em cada passagem de treinamento ou você manterá os gradientes das batches de treinamento anteriores\n",
    "        optimizer.zero_grad() \n",
    "                              \n",
    "        output = model.forward(images)     \n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Loss Treino: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_classes(image, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(image.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "image = images[0].view(1, 784)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logs = model(image)\n",
    "\n",
    "# A saída da rede são probabilidades logarítmicas\n",
    "# Precisamos transforma-las em exponenciais para dar probabilidades\n",
    "p = torch.exp(logs)\n",
    "\n",
    "show_classes(image, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- source : \n",
    "- https://www.reddit.com/r/MachineLearning/comments/l1z8cr/d_best_way_to_draw_neural_network_diagrams/\n",
    "- https://www.astroml.org/book_figures/chapter9/fig_neural_network.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
